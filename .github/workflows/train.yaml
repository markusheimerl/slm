name: Train SLM Model

on:
  workflow_dispatch:
    inputs:
      training_steps:
        description: 'Number of training steps'
        required: true
        default: '1000000'
        type: string
      batch_size:
        description: 'Batch size for training'
        required: true
        default: '64'
        type: string
      learning_rate:
        description: 'Initial learning rate'
        required: true
        default: '0.0001'
        type: string
      min_learning_rate:
        description: 'Minimum learning rate (for cosine schedule)'
        required: true
        default: '0.00001'
        type: string

permissions:
  contents: write

jobs:
  create-pod:
    runs-on: ubuntu-latest
    
    steps:
      - name: Create RunPod Instance
        id: create-pod
        run: |
          # Create a script file with the setup and training logic
          cat > setup_script.sh << 'EOF'
          cd /workspace
          
          # Set up LLVM/Clang 17 repository
          echo "deb http://apt.llvm.org/jammy/ llvm-toolchain-jammy-17 main" > /etc/apt/sources.list.d/llvm-17.list
          echo "deb-src http://apt.llvm.org/jammy/ llvm-toolchain-jammy-17 main" >> /etc/apt/sources.list.d/llvm-17.list
          wget -q -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add -
          
          apt update
          apt install -y time tree htop nvtop libcurl4-openssl-dev clang-17 gh jq
          update-alternatives --install /usr/bin/clang clang /usr/bin/clang-17 100
          
          mkdir -p slm
          cd slm
          
          # Clone repo and set up directories
          git clone --depth 1 https://github.com/$REPO_OWNER/$REPO_NAME.git .

          # Set training parameters in the SLM code
          sed -i "s/int total_training_steps = 1000000;/int total_training_steps = $TRAINING_STEPS;/" slm.c
          sed -i "s/int batch_size = 64;/int batch_size = $BATCH_SIZE;/" slm.c
          sed -i "s/float initial_lr = 0.0001f;/float initial_lr = ${LEARNING_RATE}f;/" slm.c
          sed -i "s/float min_lr = 0.00001f;/float min_lr = ${MIN_LEARNING_RATE}f;/" slm.c
          
          # Use the personal access token for authentication
          echo "$USER_PAT" > token.txt
          gh auth login --with-token < token.txt
          rm token.txt  # Remove the token file for security
          
          # Create a training log file with timestamp at the beginning
          TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
          TRAINING_LOG="${TIMESTAMP}_slm_training.log"
          touch $TRAINING_LOG
          
          # Log system info
          echo "=== System Information ===" | tee -a $TRAINING_LOG
          nvidia-smi | tee -a $TRAINING_LOG
          clang --version | tee -a $TRAINING_LOG
          echo "" | tee -a $TRAINING_LOG
          
          # Log training configuration
          echo "=== Training Configuration ===" | tee -a $TRAINING_LOG
          echo "Training Steps: $TRAINING_STEPS" | tee -a $TRAINING_LOG
          echo "Batch Size: $BATCH_SIZE" | tee -a $TRAINING_LOG
          echo "Initial Learning Rate: $LEARNING_RATE" | tee -a $TRAINING_LOG
          echo "Minimum Learning Rate: $MIN_LEARNING_RATE" | tee -a $TRAINING_LOG
          echo "" | tee -a $TRAINING_LOG
          
          # Process data - Download corpus if needed
          echo "=== Training Initialization ===" | tee -a $TRAINING_LOG
          echo "Processing data..." | tee -a $TRAINING_LOG
          make data 2>&1 | tee -a $TRAINING_LOG
          
          # Check for previous releases
          echo "Checking for previous releases..." | tee -a $TRAINING_LOG
          RELEASES=$(gh release list --limit 5 | tee -a $TRAINING_LOG || echo "")
          
          if [[ -n "$RELEASES" && "$RELEASES" != *"No releases"* ]]; then
            echo "Found previous releases. Attempting to download the most recent model." | tee -a $TRAINING_LOG
            
            # First try to get the latest release (first line)
            RELEASE_TAG=$(echo "$RELEASES" | head -n 1 | awk '{print $1}')
            echo "Latest release tag: $RELEASE_TAG" | tee -a $TRAINING_LOG
            
            # List all assets from the release to find the model file
            echo "Listing release assets:" | tee -a $TRAINING_LOG
            ASSETS=$(gh release view $RELEASE_TAG --json assets | jq -r '.assets[].name' | tee -a $TRAINING_LOG)
            
            # Look for a model file (should match *_mixer_model.bin)
            MODEL_FILE=$(echo "$ASSETS" | grep "_mixer_model.bin" | head -n 1)
            
            if [[ -n "$MODEL_FILE" ]]; then
              echo "Found model file: $MODEL_FILE" | tee -a $TRAINING_LOG
              echo "Downloading model from release $RELEASE_TAG..." | tee -a $TRAINING_LOG
              gh release download "$RELEASE_TAG" --pattern "$MODEL_FILE" 2>&1 | tee -a $TRAINING_LOG
              
              if [[ -f "$MODEL_FILE" ]]; then
                echo "Downloaded model file successfully" | tee -a $TRAINING_LOG
                echo "=== Training Process ===" | tee -a $TRAINING_LOG
                echo "Starting training continuation..." | tee -a $TRAINING_LOG
                make cont 2>&1 | tee -a $TRAINING_LOG
              else
                echo "Error: Downloaded file not found! Starting training from scratch." | tee -a $TRAINING_LOG
                echo "=== Training Process ===" | tee -a $TRAINING_LOG
                echo "Starting training from scratch..." | tee -a $TRAINING_LOG
                make run 2>&1 | tee -a $TRAINING_LOG
              fi
            else
              echo "No model file found in release assets. Starting training from scratch." | tee -a $TRAINING_LOG
              echo "=== Training Process ===" | tee -a $TRAINING_LOG
              echo "Starting training from scratch..." | tee -a $TRAINING_LOG
              make run 2>&1 | tee -a $TRAINING_LOG
            fi
          else
            echo "No previous releases found. Starting training from scratch." | tee -a $TRAINING_LOG
            echo "=== Training Process ===" | tee -a $TRAINING_LOG
            echo "Starting training from scratch..." | tee -a $TRAINING_LOG
            make run 2>&1 | tee -a $TRAINING_LOG
          fi
          
          echo "=== Training Completed ===" | tee -a $TRAINING_LOG
          
          # Find the most recent model file
          MODEL_FILE=$(ls -t *_mixer_model.bin | head -1)
          echo "Generated model file: $MODEL_FILE" | tee -a $TRAINING_LOG
          
          # Prepare release notes with the generation output and training params
          cat > release_notes.md << EOF2
          Automatically trained Mixer Language Model.
          
          ## Training Configuration
          - Training Steps: $TRAINING_STEPS
          - Batch Size: $BATCH_SIZE
          - Initial Learning Rate: $LEARNING_RATE
          - Minimum Learning Rate: $MIN_LEARNING_RATE
          
          ## Training Log
          Full training log is available in the attached log file.
          
          ## Model Information
          - Model file: $MODEL_FILE
          - Training completed: $(date)
          EOF2
          
          # Extract a sample of the generated text for the release notes
          echo -e "\n## Generation Sample Output\n" >> release_notes.md
          echo "\`\`\`" >> release_notes.md
          # Get the generated sample
          echo "$GEN_OUTPUT" | tail -30 >> release_notes.md
          echo "\`\`\`" >> release_notes.md
          
          # Create the release with the model file and log
          RELEASE_TAG="${TIMESTAMP}_slm_training"
          echo "Creating release with tag: $RELEASE_TAG" | tee -a $TRAINING_LOG
          gh release create $RELEASE_TAG $MODEL_FILE $TRAINING_LOG --title "SLM Training $TIMESTAMP" --notes-file release_notes.md
          
          echo "Release created successfully." | tee -a $TRAINING_LOG
          echo "Cleaning up..." | tee -a $TRAINING_LOG
          
          # Clean up the pod once we're done
          runpodctl remove pod $RUNPOD_POD_ID
          EOF
          
          # Base64 encode the script to avoid escaping issues
          ENCODED_SCRIPT=$(base64 -w 0 setup_script.sh)
          
          # Create the command that will be run inside the pod
          DOCKER_ARGS="bash -c 'echo $ENCODED_SCRIPT | base64 -d > /workspace/setup.sh && chmod +x /workspace/setup.sh && REPO_OWNER=${{ github.repository_owner }} REPO_NAME=${{ github.event.repository.name }} USER_PAT=${{ secrets.USER_PAT }} TRAINING_STEPS=${{ inputs.training_steps }} BATCH_SIZE=${{ inputs.batch_size }} LEARNING_RATE=${{ inputs.learning_rate }} MIN_LEARNING_RATE=${{ inputs.min_learning_rate }} /workspace/setup.sh'"

          # Submit the pod creation request to RunPod
          RESPONSE=$(curl --request POST \
            --header 'content-type: application/json' \
            --url "https://api.runpod.io/graphql?api_key=${{ secrets.RUNPOD_API_KEY }}" \
            --data "$(jq -n \
              --arg docker_args "$DOCKER_ARGS" \
              '{
                "query": "mutation($input: PodFindAndDeployOnDemandInput!) { podFindAndDeployOnDemand(input: $input) { id imageName machineId } }",
                "variables": {
                  "input": {
                    "cloudType": "SECURE",
                    "gpuCount": 1,
                    "volumeInGb": 10,
                    "containerDiskInGb": 20,
                    "minVcpuCount": 4,
                    "minMemoryInGb": 20,
                    "gpuTypeId": "NVIDIA GeForce RTX 4090",
                    "name": "slm-training",
                    "imageName": "runpod/pytorch:2.4.0-py3.11-cuda12.4.1-devel-ubuntu22.04",
                    "ports": "8888/http,22/tcp,8080/http",
                    "volumeMountPath": "/workspace",
                    "dockerArgs": $docker_args
                  }
                }
              }'
            )")

          echo "Response: $RESPONSE"
          
          if echo "$RESPONSE" | grep -q "error"; then
            echo "Error creating pod"
            echo "$RESPONSE"
            exit 1
          fi
          
          POD_ID=$(echo "$RESPONSE" | jq -r '.data.podFindAndDeployOnDemand.id')
          if [[ -z "$POD_ID" || "$POD_ID" == "null" ]]; then
            echo "Failed to get pod ID from response"
            exit 1
          fi
          
          echo "Created pod with ID: $POD_ID"
          echo "pod_id=$POD_ID" >> $GITHUB_OUTPUT
          
          echo "Pod has been started."